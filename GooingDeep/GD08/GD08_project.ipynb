{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d38cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import transformers\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d275421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n",
      "4.11.3\n",
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(transformers.__version__)\n",
    "print(datasets.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8988f44e",
   "metadata": {},
   "source": [
    "#### step1. NSMC 데이터 분석 및 Huggingface dataset 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "839789f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset nsmc (/aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345fe98b4424433988670a5f9adf89fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'document', 'label'],\n",
      "        num_rows: 150000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'document', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import list_datasets, load_dataset, list_metrics, load_metric\n",
    "from huggingface_hub.hf_api import HfFolder\n",
    "\n",
    "\n",
    "huggingface_nsmc_dataset = load_dataset('nsmc')\n",
    "print(huggingface_nsmc_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bec843a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'document', 'label']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = huggingface_nsmc_dataset['train']\n",
    "cols = train.column_names\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33682e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'document', 'label'],\n",
       "    num_rows: 150000\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b6035c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'document', 'label'],\n",
       "    num_rows: 50000\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = huggingface_nsmc_dataset['test']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "449b01c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : 9976970\n",
      "document : 아 더빙.. 진짜 짜증나네요 목소리\n",
      "label : 0\n",
      "\n",
      "\n",
      "id : 3819312\n",
      "document : 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
      "label : 1\n",
      "\n",
      "\n",
      "id : 10265843\n",
      "document : 너무재밓었다그래서보는것을추천한다\n",
      "label : 0\n",
      "\n",
      "\n",
      "id : 9045019\n",
      "document : 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
      "label : 0\n",
      "\n",
      "\n",
      "id : 6483659\n",
      "document : 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n",
      "label : 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "for i in range(5):\n",
    "    for col in cols:\n",
    "        print(col, \":\", train[col][i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90bb1f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : 6270596\n",
      "document : 굳 ㅋ\n",
      "label : 1\n",
      "\n",
      "\n",
      "id : 9274899\n",
      "document : GDNTOPCLASSINTHECLUB\n",
      "label : 0\n",
      "\n",
      "\n",
      "id : 8544678\n",
      "document : 뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n",
      "label : 0\n",
      "\n",
      "\n",
      "id : 6825595\n",
      "document : 지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n",
      "label : 0\n",
      "\n",
      "\n",
      "id : 6723715\n",
      "document : 3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n",
      "label : 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "for i in range(5):\n",
    "    for col in cols:\n",
    "        print(col, \":\", test[col][i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a16abd",
   "metadata": {},
   "source": [
    "#### step2. Klue/bert-base model 및 tokenizer 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc94b1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_checkpoint = \"klue/bert-base\"\n",
    "num_labels = 2\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d0f8052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 23044, 2088, 4390, 2062, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('배고프고 힘들다')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a819e",
   "metadata": {},
   "source": [
    "#### step3. 위에서 불러온 tokenizer으로 데이터셋을 전처리하고, model 학습 진행해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7833b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "len(train['document'])\n",
    "\n",
    "train_dataset = pd.DataFrame({'id':train['id'],\n",
    "                             'document':train['document'],\n",
    "                             'label':train['label']})\n",
    "\n",
    "test_dataset_none = pd.DataFrame({'id':test['id'],\n",
    "                             'document':test['document'],\n",
    "                             'label':test['label']})\n",
    "\n",
    "# student_card\n",
    "train_dataset[:5]\n",
    "val_dataset = test_dataset_none[:int(len(test_dataset_none)/2)]\n",
    "test_dataset = test_dataset_none[int(len(test_dataset_none)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4acd58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n",
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c4dd1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>6222902</td>\n",
       "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>8549745</td>\n",
       "      <td>평점이 너무 낮아서...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>9311800</td>\n",
       "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>2376369</td>\n",
       "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>9619869</td>\n",
       "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           document  label\n",
       "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "...          ...                                                ...    ...\n",
       "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
       "149996   8549745                                      평점이 너무 낮아서...      1\n",
       "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
       "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
       "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
       "\n",
       "[150000 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb0f3d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75173\n",
       "1    74827\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ffdc626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_counts = train_dataset['label'].value_counts()\n",
    "label_names = ['negative','positive']\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(label_names, label_counts, color=['red','blue'])\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ad9d60",
   "metadata": {},
   "source": [
    "=> label의 분포 확인 결과 불균형없음을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "816f8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# DataFrame 데이터를 dict 내부에 list로 변경\n",
    "train_dataset = train_dataset.to_dict(orient='list')\n",
    "val_dataset = val_dataset.to_dict('list')\n",
    "test_dataset = test_dataset.to_dict('list')\n",
    "\n",
    "# Hugging Face dataset으로 변환\n",
    "tf_train_dataset = Dataset.from_dict(train_dataset)\n",
    "tf_val_dataset = Dataset.from_dict(val_dataset)\n",
    "tf_test_dataset = Dataset.from_dict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f8db313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# 분할된 데이터셋을 DatasetDict 형태로 조합\n",
    "hf_dataset_dict = DatasetDict({\n",
    "    'train': tf_train_dataset,\n",
    "    'validation': tf_val_dataset,\n",
    "    'test': tf_test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "520feaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'document', 'label'],\n",
       "        num_rows: 150000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'document', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'document', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9a6f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련데이터로부터 샘플을 불러와 토크나이저 적용\n",
    "\n",
    "# 변환 함수 정의\n",
    "def transform(data):\n",
    "    return tokenizer(\n",
    "        data['document'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length = 80,\n",
    "        return_token_type_ids=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f5b8b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63f26780a6c41919dfcc2053a665a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49cccb63d5174a2f9970ee9959fabdeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_dataset = huggingface_nsmc_dataset.map(transform, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e1f9a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be6b79200a1486e806fc2eb06aecde5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ccbb37abd9460fa5a33ddcac0b71a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fb64244cf245288bbcc89f9ea1f066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_dataset = hf_dataset_dict.map(transform, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbe0ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric('glue', 'mrpc')\n",
    "\n",
    "def compute_metrics(eval_pred):    \n",
    "    predictions,labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f488042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련, 검증, 테스트 데이터셋 분할\n",
    "hf_train_dataset = hf_dataset['train']\n",
    "hf_val_dataset = hf_dataset['validation']\n",
    "hf_test_dataset = hf_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5753c3",
   "metadata": {},
   "source": [
    "시간을 고려해서 epoch과 batch_size를 대폭 줄여서 실험을 진행\n",
    "- batch_size=4\n",
    "- epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3aa6fead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir,                                         # output이 저장될 경로\n",
    "    evaluation_strategy=\"epoch\",           #evaluation하는 빈도\n",
    "    learning_rate = 2e-5,                         #learning_rate\n",
    "    per_device_train_batch_size = 4,   # 각 device 당 batch size\n",
    "    per_device_eval_batch_size = 4,    # evaluation 시에 batch size\n",
    "    num_train_epochs = 1,                     # train 시킬 총 epochs\n",
    "    weight_decay = 0.005,                        # weight decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9652feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,           # 학습시킬 model\n",
    "    args=training_arguments,           # TrainingArguments을 통해 설정한 arguments\n",
    "    train_dataset=hf_train_dataset,    # training dataset\n",
    "    eval_dataset=hf_val_dataset,       # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8d18391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: document, id.\n",
      "***** Running training *****\n",
      "  Num examples = 150000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37500' max='37500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37500/37500 1:24:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.419600</td>\n",
       "      <td>0.430858</td>\n",
       "      <td>0.900480</td>\n",
       "      <td>0.901481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-1500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-1500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-2000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-2000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-2500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-2500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-3000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-3000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-3500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-3500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-4000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-4000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-4500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-4500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-5000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-5000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-5500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-5500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-6000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-6000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-6000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-6500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-6500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-6500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-7000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-7000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-7000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-7500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-7500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-7500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-8000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-8000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-8000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-8500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-8500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-8500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-9000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-9000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-9000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-9500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-9500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-9500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-10000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-10000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-10000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-10500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-10500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-11000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-11000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-11000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-11500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-11500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-11500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-12000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-12000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-12000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-12500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-12500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-12500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-13000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-13000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-13000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-13500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-13500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-13500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-14000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-14000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-14000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-14500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-14500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-14500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-15000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-15000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-15000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-15500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-15500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-15500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-16000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-16000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-16000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-16500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-16500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-16500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-17000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-17000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-17000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-17500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-17500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-17500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-18000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-18000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-18000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-18500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-18500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-18500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-19000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-19000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-19000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-19500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-19500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-19500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-20000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-20000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-20000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-20500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-20500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-20500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-21000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-21000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-21000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-21500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-21500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-21500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-22000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-22000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-22000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-22500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-22500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-22500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-23000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-23000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-23000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-23500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-23500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-23500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-24000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-24000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-24000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-24500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-24500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-24500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-25000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-25000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-25000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-25500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-25500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-25500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-26000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-26000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-26000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-26500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-26500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-26500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-27000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-27000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-27000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-27500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-27500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-27500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-28000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-28000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-28000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-28500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-28500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-28500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-29000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-29000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-29000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-29500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-29500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-29500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-30000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-30000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-30000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-30500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-30500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-30500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-31000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-31000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-31000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-31500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-31500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-31500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-32000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-32000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-32000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-32500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-32500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-32500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-33000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-33000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-33000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-33500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-33500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-33500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-34000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-34000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-34000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-34500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-34500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-34500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-35000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-35000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-35000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-35500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-35500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-35500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-36000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-36000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-36000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-36500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-36500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-36500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-37000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-37000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-37000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-37500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-37500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-37500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: document, id.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=37500, training_loss=0.2768705303955078, metrics={'train_runtime': 5095.0807, 'train_samples_per_second': 29.44, 'train_steps_per_second': 7.36, 'total_flos': 6166665360000000.0, 'train_loss': 0.2768705303955078, 'epoch': 1.0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6018b720",
   "metadata": {},
   "source": [
    "- 훈련 loss : 0.419600\n",
    "- val loss : 0.430858\n",
    "- 정확도 : 0.900480\n",
    "- f1 score : 0.901481"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8be0e8",
   "metadata": {},
   "source": [
    "#### step 4. Fine-tuning을 통하여 모델 성능 향상시키기\n",
    "- 데이터 전처리, TrainingArguments 등을 조정하여 모델의 정확도를 90% 이상으로 끌어올려봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c108166",
   "metadata": {},
   "source": [
    "weight_decay를 0.005에서 0.01로 늘려서 실험을 진행해보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5e83cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir,                                         # output이 저장될 경로\n",
    "    evaluation_strategy=\"epoch\",           #evaluation하는 빈도\n",
    "    learning_rate = 2e-5,                         #learning_rate\n",
    "    per_device_train_batch_size = 4,   # 각 device 당 batch size\n",
    "    per_device_eval_batch_size = 4,    # evaluation 시에 batch size\n",
    "    num_train_epochs = 1,                     # train 시킬 총 epochs\n",
    "    weight_decay = 0.01,                        # weight decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ec42ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,           # 학습시킬 model\n",
    "    args=training_arguments,           # TrainingArguments을 통해 설정한 arguments\n",
    "    train_dataset=hf_train_dataset,    # training dataset\n",
    "    eval_dataset=hf_val_dataset,       # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d992b1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: document, id.\n",
      "***** Running training *****\n",
      "  Num examples = 150000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37500' max='37500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37500/37500 1:08:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.392900</td>\n",
       "      <td>0.384178</td>\n",
       "      <td>0.903400</td>\n",
       "      <td>0.904254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-1500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-1500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-2000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-2000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-2500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-2500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-3000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-3000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-3500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-3500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-4000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-4000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-4500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-4500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-5000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-5000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-5500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-5500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-6000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-6000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-6000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-6500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-6500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-6500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-7000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-7000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-7000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-7500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-7500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-7500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-8000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-8000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-8000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-8500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-8500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-8500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-9000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-9000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-9000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-9500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-9500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-9500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-10000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-10000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-10000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-10500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-10500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-11000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-11000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-11000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-11500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-11500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-11500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-12000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-12000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-12000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-12500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-12500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-12500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-13000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-13000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-13000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-13500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-13500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-13500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-14000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-14000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-14000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-14500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-14500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-14500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-15000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-15000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-15000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-15500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-15500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-15500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-16000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-16000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-16000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-16500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-16500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-16500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-17000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-17000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-17000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-17500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-17500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-17500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-18000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-18000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-18000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-18500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-18500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-18500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-19000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-19000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-19000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-19500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-19500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-19500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-20000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-20000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-20000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-20500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-20500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-20500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-21000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-21000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-21000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-21500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-21500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-21500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-22000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-22000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-22000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-22500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-22500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-22500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-23000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-23000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-23000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-23500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-23500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-23500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-24000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-24000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-24000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-24500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-24500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-24500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-25000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-25000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-25000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-25500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-25500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-25500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-26000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-26000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-26000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-26500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-26500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-26500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-27000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-27000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-27000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-27500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-27500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-27500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-28000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-28000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-28000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-28500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-28500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-28500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-29000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-29000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-29000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-29500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-29500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-29500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-30000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-30000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-30000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-30500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-30500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-30500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-31000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-31000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-31000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-31500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-31500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-31500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-32000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-32000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-32000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-32500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-32500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-32500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-33000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-33000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-33000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-33500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-33500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-33500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-34000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-34000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-34000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-34500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-34500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-34500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-35000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-35000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-35000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-35500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-35500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-35500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-36000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-36000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-36000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-36500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-36500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-36500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-37000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-37000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-37000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-37500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-37500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-37500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: document, id.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=37500, training_loss=0.41807968994140626, metrics={'train_runtime': 4131.1641, 'train_samples_per_second': 36.309, 'train_steps_per_second': 9.077, 'total_flos': 6166665360000000.0, 'train_loss': 0.41807968994140626, 'epoch': 1.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8385522d",
   "metadata": {},
   "source": [
    "- 훈련 loss : 0.392900\n",
    "- val loss : 0.384178\n",
    "- accuracy : 0.903400\n",
    "- F1 score : 0.904254\n",
    "\n",
    "=> 정규화기법이여서 성능이 아주 약간 향상됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668613b1",
   "metadata": {},
   "source": [
    "#### step 5. Bucketing을 적용하여 학습시키고, step 4의 결과와 비교\n",
    "- 아래 링크를 바탕으로 bucketing과 dynamic padding이 무엇인지 알아보고, 이들을 적용하여 model을 학습시킵니다.\n",
    "- STEP 4에 학습한 결과와 bucketing을 적용하여 학습시킨 결과를 비교해보고, 모델 성능 향상과 훈련 시간 두 가지 측면에서 각각 어떤 이점이 있는지 비교해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0b8f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# 데이터 콜레이터 정의 (Bucketing을 포함한 패딩 적용)\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer,  # 사용 중인 토크나이저\n",
    "    padding=True)  # 패딩을 적용하도록 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "62bef3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "# 훈련 파라미터 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,  # 모델과 결과물 저장 경로\n",
    "    evaluation_strategy=\"epoch\",           #evaluation하는 빈도\n",
    "    learning_rate = 2e-5,                         #learning_rate\n",
    "    per_device_train_batch_size = 4,   # 각 device 당 batch size\n",
    "    num_train_epochs = 1,                     # train 시킬 총 epochs\n",
    "    weight_decay = 0.01,                        # weight decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "20c01882",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,           # 학습시킬 model\n",
    "    args=training_arguments,           # TrainingArguments을 통해 설정한 arguments\n",
    "    data_collator = data_collator,\n",
    "    train_dataset=hf_train_dataset,    # training dataset\n",
    "    eval_dataset=hf_val_dataset,       # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "776214c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: document, id.\n",
      "***** Running training *****\n",
      "  Num examples = 150000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37500\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37500' max='37500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37500/37500 1:24:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.485600</td>\n",
       "      <td>0.478792</td>\n",
       "      <td>0.898040</td>\n",
       "      <td>0.898369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-1000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-1500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-1500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-1500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-2000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-2000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-2000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-2500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-2500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-2500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-3000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-3000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-3000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-3500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-3500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-3500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-4000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-4000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-4000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-4500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-4500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-4500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-5000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-5000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-5000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-5500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-5500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-5500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-6000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-6000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-6000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-6500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-6500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-6500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-7000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-7000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-7000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-7500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-7500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-7500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-8000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-8000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-8000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-8500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-8500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-8500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-9000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-9000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-9000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-9500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-9500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-9500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-10000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-10000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-10000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-10500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-10500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-10500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-11000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-11000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-11000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-11500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-11500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-11500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-12000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-12000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-12000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-12500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-12500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-12500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-13000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-13000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-13000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-13500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-13500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-13500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-14000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-14000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-14000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-14500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-14500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-14500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-15000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-15000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-15000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-15500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-15500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-15500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-16000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-16000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-16000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-16500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-16500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-16500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-17000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-17000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-17000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-17500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-17500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-17500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-18000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-18000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-18000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-18500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-18500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-18500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-19000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-19000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-19000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-19500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-19500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-19500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-20000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-20000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-20000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-20500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-20500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-20500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-21000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-21000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-21000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-21500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-21500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-21500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-22000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-22000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-22000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-22500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-22500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-22500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-23000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-23000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-23000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-23500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-23500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-23500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-24000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-24000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-24000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-24500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-24500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-24500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-25000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-25000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-25000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-25500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-25500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-25500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-26000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-26000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-26000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-26500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-26500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-26500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-27000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-27000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-27000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-27500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-27500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-27500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-28000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-28000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-28000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-28500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-28500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-28500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-29000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-29000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-29000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-29500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-29500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-29500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-30000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-30000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-30000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-30500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-30500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-30500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-31000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-31000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-31000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-31500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-31500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-31500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-32000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-32000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-32000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-32500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-32500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-32500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-33000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-33000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-33000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-33500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-33500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-33500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-34000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-34000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-34000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-34500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-34500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-34500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-35000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-35000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-35000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-35500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-35500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-35500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-36000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-36000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-36000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-36500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-36500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-36500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-37000\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-37000/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-37000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to /aiffel/aiffel/prj/checkpoint-37500\n",
      "Configuration saved in /aiffel/aiffel/prj/checkpoint-37500/config.json\n",
      "Model weights saved in /aiffel/aiffel/prj/checkpoint-37500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: document, id.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 4\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=37500, training_loss=0.18389512908935546, metrics={'train_runtime': 5080.867, 'train_samples_per_second': 29.523, 'train_steps_per_second': 7.381, 'total_flos': 6166665360000000.0, 'train_loss': 0.18389512908935546, 'epoch': 1.0})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c848157",
   "metadata": {},
   "source": [
    "회고\n",
    "- 허깅페이스를 통해 트렌스포머 모델을 가져오기 편하고 파인튜닝된 다양한 모델을 쉽게 가져올 수 있다는 점에서 유용하게 쓰이는 이유에 대해서 잘 알 수 있었고 직접 가져와 사용해볼 수 있었다.\n",
    "- 아직 bucketing을 사용할 경우 성능이 좋아질 거라고 생각했지만 정확도가 떨어진 이유에 대해서는 훈련을 잘못시킨 것 같은데 다시 시간적여유를 가지고 재시도해봐야할 것 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
